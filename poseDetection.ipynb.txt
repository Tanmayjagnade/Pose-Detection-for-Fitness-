{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
      "ERROR: No matching distribution found for pickle\n"
     ]
    }
   ],
   "source": [
    "pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils     # Connecting Keypoints Visuals\n",
    "mp_pose = mp.solutions.pose                 # Keypoint detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark Positions\n",
    "1. We will need the angle at the elbow to count the number of curls and also to determine incorrect curl during the exercise. We will figure it out using the coordinates of shoulder, elbow and wrist.\n",
    "\n",
    "![Keypoints](https://google.github.io/mediapipe/images/mobile/pose_tracking_full_body_landmarks.png)\n",
    "* Image Source: https://google.github.io/mediapipe/solutions/pose.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are concerned with only three keypoints that are shoulder, elbow and wrist of the same hand; be it either left or right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal number of landmarks = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(\u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark)))\n\u001b[0;32m      2\u001b[0m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;66;03m# Output of first two landmarks in the container\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Total number of landmarks = {}\".format(len(results.pose_landmarks.landmark)))\n",
    "results.pose_landmarks.landmark[0:2] # Output of first two landmarks in the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 PoseLandmark.NOSE\n",
      "1 PoseLandmark.LEFT_EYE_INNER\n",
      "2 PoseLandmark.LEFT_EYE\n",
      "3 PoseLandmark.LEFT_EYE_OUTER\n",
      "4 PoseLandmark.RIGHT_EYE_INNER\n",
      "5 PoseLandmark.RIGHT_EYE\n",
      "6 PoseLandmark.RIGHT_EYE_OUTER\n",
      "7 PoseLandmark.LEFT_EAR\n",
      "8 PoseLandmark.RIGHT_EAR\n",
      "9 PoseLandmark.MOUTH_LEFT\n",
      "10 PoseLandmark.MOUTH_RIGHT\n",
      "11 PoseLandmark.LEFT_SHOULDER\n",
      "12 PoseLandmark.RIGHT_SHOULDER\n",
      "13 PoseLandmark.LEFT_ELBOW\n",
      "14 PoseLandmark.RIGHT_ELBOW\n",
      "15 PoseLandmark.LEFT_WRIST\n",
      "16 PoseLandmark.RIGHT_WRIST\n",
      "17 PoseLandmark.LEFT_PINKY\n",
      "18 PoseLandmark.RIGHT_PINKY\n",
      "19 PoseLandmark.LEFT_INDEX\n",
      "20 PoseLandmark.RIGHT_INDEX\n",
      "21 PoseLandmark.LEFT_THUMB\n",
      "22 PoseLandmark.RIGHT_THUMB\n",
      "23 PoseLandmark.LEFT_HIP\n",
      "24 PoseLandmark.RIGHT_HIP\n",
      "25 PoseLandmark.LEFT_KNEE\n",
      "26 PoseLandmark.RIGHT_KNEE\n",
      "27 PoseLandmark.LEFT_ANKLE\n",
      "28 PoseLandmark.RIGHT_ANKLE\n",
      "29 PoseLandmark.LEFT_HEEL\n",
      "30 PoseLandmark.RIGHT_HEEL\n",
      "31 PoseLandmark.LEFT_FOOT_INDEX\n",
      "32 PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "# Sequential mapping of the landmarks with human body parts\n",
    "\n",
    "count = 0\n",
    "for i in mp_pose.PoseLandmark:\n",
    "    print(count, i)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angle(a,b,c): # 3D points\n",
    "    ''' Arguments:\n",
    "        a,b,c -- Values (x,y,z, visibility) of the three points a, b and c which will be used to calculate the\n",
    "                vectors ab and bc where 'b' will be 'elbow', 'a' will be shoulder and 'c' will be wrist.\n",
    "        \n",
    "        Returns:\n",
    "        theta : Angle in degress between the lines joined by coordinates (a,b) and (b,c)\n",
    "    '''\n",
    "    a = np.array([a.x, a.y])#, a.z])    # Reduce 3D point to 2D\n",
    "    b = np.array([b.x, b.y])#, b.z])    # Reduce 3D point to 2D\n",
    "    c = np.array([c.x, c.y])#, c.z])    # Reduce 3D point to 2D\n",
    "\n",
    "    ab = np.subtract(a, b)\n",
    "    bc = np.subtract(b, c)\n",
    "    \n",
    "    theta = np.arccos(np.dot(ab, bc) / np.multiply(np.linalg.norm(ab), np.linalg.norm(bc)))     # A.B = |A||B|cos(x) where x is the angle b/w A and B\n",
    "    theta = 180 - 180 * theta / 3.14    # Convert radians to degrees\n",
    "    return np.round(theta, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = None     # Flag which stores hand position(Either UP or DOWN)\n",
    "count = 0       # Storage for count of bicep curls\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.5) # Lnadmark detection model instance\n",
    "while cap.isOpened():\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)      # Convert BGR frame to RGB\n",
    "    image.flags.writeable = False\n",
    "    \n",
    "    # Make Detections\n",
    "    results = pose.process(image)                       # Get landmarks of the object in frame from the model\n",
    "\n",
    "    # Back to BGR\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)      # Convert RGB back to BGR\n",
    "\n",
    "    try:\n",
    "        # Extract Landmarks\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "        elbow = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
    "        wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "\n",
    "\n",
    "        # Calculate angle\n",
    "        angle = calc_angle(shoulder, elbow, wrist)      #  Get angle \n",
    "\n",
    "\n",
    "        # Visualize angle\n",
    "        cv2.putText(image,\\\n",
    "                str(angle), \\\n",
    "                    tuple(np.multiply([elbow.x, elbow.y], [640,480]).astype(int)),\\\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255),2,cv2.LINE_AA)\n",
    "    \n",
    "        # Counter \n",
    "        if angle > 160:\n",
    "            flag = 'down'\n",
    "        if angle < 40 and flag=='down':\n",
    "            count += 1\n",
    "            flag = 'up'\n",
    "            print(\"Count: {}, Flag: {}\".format(count, flag))\n",
    "        \n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Setup Status Box\n",
    "    cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n",
    "    cv2.putText(image, str(count), (10,60), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Render Detections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "\n",
    "    cv2.imshow('MediaPipe feed', image)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"model\"\n",
    "tf.saved_model.save(model, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiceps_pose\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mdump(model,\u001b[38;5;28mopen\u001b[39m(filename,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "filename =\"biceps_pose\"\n",
    "pickle.dump(model,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "1. Pose Classification [https://google.github.io/mediapipe/solutions/pose_classification.html]\n",
    "\n",
    "2. MediaPipePoseEstimation [https://github.com/nicknochnack/MediaPipePoseEstimation]\n",
    "\n",
    "3. Guide to Human Pose Estimation with Deep Learning[https://nanonets.com/blog/human-pose-estimation-2d-guide/]\n",
    "\n",
    "4. Real-time Human Pose Estimation in the Browser [https://blog.tensorflow.org/2018/05/real-time-human-pose-estimation-in.html]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "314b2b212b00368ea6d1c6877b1dbc2a73dd90aa9dffa5daa0180d41c15719c2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
